# Ollama

Ollama lets you run LLMs locally with just a few commands. It is available on macOS, Linux, and Windows. Learn more at the [Ollama website](https://ollama.com/).

This directory contains Ollama deployment guide for MiniCPM-o 4.5.

## Deployment Guide

- MiniCPM-o 4.5: [English](./minicpm-o4_5_ollama.md) | [中文](./minicpm-o4_5_ollama_zh.md)
